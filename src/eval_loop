# **** TO DO:
# 0. MOST IMPORTANT; add a method to be able to perform inference without the envcoder -> and add a sample method
# 1. Add Batch Norm
# 2. for the embedder add msking
# 3. adjust lr
# 4. adjust network size
# 5. Can I get rid of the linear layers?

import torch
from torch.utils.data import random_split
from dataset import ShapeDataset, custom_collate_fn
from networks.cvae_bn_one_old import CVAE
import numpy as np
from loss import loss_function
from tqdm import tqdm
import torchvision.models as models
import cv2
import torch.nn.functional as F
vgg11 = models.vgg11(pretrained=True).features
for param in vgg11.parameters():
    param.requires_grad = False
vgg11.to('cuda')
vgg11.eval()

seed = 42
torch.manual_seed(seed)


device  ='cuda'
model = CVAE()
# LOAD STATE DICT IF NEEDED
model.load_state_dict(torch.load('weights/model_weights_epoch_0.pth'))
num_epochs = 300
#beta = 1
beta = 0.01
batch_size = 32

dataset = ShapeDataset('dataset_one', 'dataset_one.json')
train_size = int(0.8 * len(dataset))
val_size = len(dataset) - train_size
train_dataset, val_dataset = random_split(dataset, [train_size, val_size])

val_dataloader = torch.utils.data.DataLoader(val_dataset, batch_size=batch_size, collate_fn=custom_collate_fn, drop_last=True)
train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, collate_fn=custom_collate_fn, drop_last=True)


model.to(device)

optimizer = torch.optim.Adam(model.parameters(), lr=0.000001)

for epoch in range(num_epochs):

    epoch_loss = 0
    epoch_recon_loss = 0
    epoch_kl_loss = 0
    model.eval()
    with torch.no_grad():
        torch.cuda.empty_cache()
        for batch in tqdm(val_dataloader):
            images, padded_conditioning_vectors, lengths = batch
            
            images = torch.tensor(np.transpose(images, (0, 3, 1, 2)).contiguous(), dtype=torch.float32).to(device)
            padded_conditioning_vectors = torch.tensor(padded_conditioning_vectors, dtype=torch.float32).to(device)
            lengths = lengths.to(device)
            
            reconstructed_image, m, log_v = model(images, padded_conditioning_vectors, lengths)
            

            loss, recon_loss, kl_loss = loss_function(reconstructed_image, images, m, log_v, beta, vgg11, algo='ssim')
            print('loss: ', loss)
            print('recon_loss: ', recon_loss)
            print('kl_loss: ', kl_loss)

            # ********** print

            reconstructed_image = reconstructed_image[0, :, :, :].squeeze(0)

            print(reconstructed_image.shape)
            final_layer = F.sigmoid
            reconstructed_image = final_layer(reconstructed_image)
            img = cv2.cvtColor(np.uint8(255*np.transpose(reconstructed_image.cpu().detach().numpy(), (1, 2, 0))), cv2.COLOR_RGB2BGR)
            

            cv2.imshow('Image', img)
            cv2.waitKey(0)
            cv2.destroyAllWindows()

            cv2.imwrite('generated_image.png', img)

    
